---
title: "Unit transformation strategy comparison for Model-based analysis of isobarically labeled proteomic data."
author: "Joris Van Houtven, Piotr Prostko"
date: '`r format(Sys.time(), "%B %d, %Y,%H:%M")`'
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
    theme: flatly
    code_folding: "hide"
editor_options: 
  chunk_output_type: console
---

```{r, setup, include=FALSE}
# default knitr options for all chunks
knitr::opts_chunk$set(
  message=FALSE,
  warning=FALSE,
  fig.width=12,
  fig.height=7
)
```

```{r}
library(caret)
library(lme4)
library(lmerTest)
library(ggplot2)
library(stringi)
library(gridExtra)
library(ggfortify)
library(dendextend)
library(psych)
library(kableExtra)
library(tidyverse)
library(dtplyr)
source('other_functions.R')
source('plotting_functions.R')
```

This notebook presents isobaric labeling data analysis strategy that includes model-based normalization [data-driven normalization]. 

We will check how varying analysis components [unit/summarization/normalization/differential abundance testing methods] changes end results of a quantitative proteomic study.

```{r}
data.list <- readRDS('input_data.rds')
dat.l <- data.list$dat.l # data in long format

# keep spectra with (isolation interference <=30 or NA) and no missing quantification channels
dat.l <- dat.l %>% filter(isoInterOk & noNAs)

# which proteins were spiked in?
spiked.proteins <- dat.l %>% distinct(Protein) %>% filter(stri_detect(Protein, fixed='ups')) %>% pull %>% as.character

#TEMP -remove!
# tmp=dat.l %>% distinct(Protein) %>% pull %>% as.character
# dat.l <- dat.l %>% filter(Protein %in% c(tmp[sample(1:length(tmp), size=20)], spiked.proteins))
```

```{r}
# specify # of varying component variants and their names
variant.names <- c('log2Intensity', 'Intensity', 'Ratio')
n.comp.variants <- length(variant.names)
scale.vec <- c('log', 'raw', 'raw') # ratios are considered raw, because they are basically mean-normalized intensities
# pick reference condition for making plots / doing DEA
referenceCondition <- '0.5'
# specify colours corresponding to biological conditions
condition.colour <- tribble(
  ~Condition, ~Colour,
  "0.125", 'black',
  "0.5", 'blue',
  "0.667", 'green',
  "1", 'red' )
# create data frame with sample info (distinct Run,Channel, Condition, Colour)
sample.info <- get_sample_info(dat.l, condition.colour)
```

# Unit component

```{r}
dat.unit.l <- emptyList(variant.names)
```

## log2 transformation of reporter ion intensities

```{r}
dat.unit.l$log2Intensity <- dat.l %>% mutate(response=log2(Intensity)) %>% select(-Intensity)
```

## original scale (not log2-transformed) of reporter ion intensities
```{r}
dat.unit.l$Intensity <- dat.l %>% rename(response=Intensity)
```

## intensity ratios (with respect to average within run)

Calculate ratio's (per PSM) with respect to average intensity within run, 
or in other words: each value is divided by the row mean.

```{r}
# use half-wide data to compute within-run average of PSM channels corresponding to the reference Condition
refCols <- sample.info %>% filter(Condition==referenceCondition) %>% distinct(Channel) %>% pull
denom.df=dat.l %>% filter(Condition==referenceCondition) %>% pivot_wider(id_cols=-one_of('Condition', 'BioReplicate'),names_from='Channel', values_from='Intensity')
denom.df$denom=apply(denom.df[,refCols], 1, function(x) mean(x, na.rm=T))
denom.df=denom.df[,c('Run', 'Protein', 'Peptide', 'RT', 'Charge', 'PTM', 'denom')]
dat.unit.l$Ratio <- dat.l %>% left_join(denom.df[c('Run', 'Protein', 'Peptide', 'RT', 'Charge', 'PTM', 'denom')], by=c('Run', 'Protein', 'Peptide', 'RT', 'Charge', 'PTM')) %>% mutate(response=Intensity/denom) %>% select(-c(Intensity, denom)) 
```

# Summarization component

```{r}
# no summarization 
dat.summ.l <- dat.unit.l
```

## no summarization

# Normalization component

## mixed model spec 1

```{r}
dat.norm.l <- dat.summ.l
# fit normalization model
norm.models <- lapply(dat.summ.l, function(x) return(lmer(response ~ Mixture + Mixture:TechRepMixture + Mixture:TechRepMixture:Channel + (1|Protein) + (1|Mixture:TechRepMixture:Peptide), data=x)))
# assign normalized values
for (i in seq_along(variant.names)){ dat.norm.l[[variant.names[i]]]$response <- residuals(norm.models[[variant.names[i]]]) }
# apply the 'fix' - add the model intercept to the residuals
dat.norm.l$IntensityFix <- dat.norm.l$Intensity; dat.norm.l$IntensityFix$response <- dat.norm.l$IntensityFix$response + fixef(norm.models$Intensity)['(Intercept)']
dat.norm.l$RatioFix <- dat.norm.l$Ratio; dat.norm.l$RatioFix$response <- dat.norm.l$RatioFix$response + fixef(norm.models$Ratio)['(Intercept)']
# update variant names, #, scale
variant.names <- names(dat.norm.l)
scale.vec <- c(scale.vec, 'raw', 'raw')
n.comp.variants <- length(variant.names)
tmp <- c("log2Intensity", "Intensity", "IntensityFix", "Ratio", "RatioFix")
variant.names <- tmp
dat.norm.l <- dat.norm.l[tmp]
# for technical reasons, assign new variants to dat.summ.l
dat.summ.l$IntensityFix <- dat.summ.l$Intensity
dat.summ.l$RatioFix <- dat.summ.l$Ratio
dat.summ.l <- dat.summ.l[tmp]
```

# QC plots

```{r}
# PSM data needs to be aggregated prior to PCA plots and HC plots (they require features in the intersection of all MS runs - this is not possible for PSM data). In order to be consisent, other normalization plots will be based on the aggregated data
dat.nonnorm.summ.l <- lapply(dat.summ.l, function(x) aggFunc(x, 'response', group.vars=c('Mixture', 'TechRepMixture', 'Run', 'Channel', 'Condition', 'BioReplicate', 'Protein', 'Peptide'), 'median')) # before normalization (you still need to aggregate the data because of 'dat.summ.l <- dat.unit.l' operation)
dat.nonnorm.summ.l <- lapply(dat.nonnorm.summ.l, function(x) aggFunc(x, 'response', group.vars=c('Mixture', 'TechRepMixture', 'Run', 'Channel', 'Condition', 'BioReplicate', 'Protein'), 'median'))
dat.norm.summ.l <- lapply(dat.norm.l, function(x) aggFunc(x, 'response', group.vars=c('Mixture', 'TechRepMixture', 'Run', 'Channel', 'Condition', 'BioReplicate', 'Protein', 'Peptide'), 'median')) # after normalization
dat.norm.summ.l <- lapply(dat.norm.summ.l, function(x) aggFunc(x, 'response', group.vars=c('Mixture', 'TechRepMixture', 'Run', 'Channel', 'Condition', 'BioReplicate', 'Protein'), 'median')) # after normalization

# now create data sets in wide format
# before normalization
dat.nonnorm.summ.w <- lapply(dat.nonnorm.summ.l, function(x) {
  dat.tmp <- pivot_wider(data=x, id_cols=Protein, names_from=Run:Channel, values_from=response, names_sep=':') %>% column_to_rownames('Protein')
  return(dat.tmp) } )

# after normalization
dat.norm.summ.w <- lapply(dat.norm.summ.l, function(x) {
  dat.tmp <- pivot_wider(data=x, id_cols=Protein, names_from=Run:Channel, values_from=response, names_sep=':') %>% column_to_rownames('Protein')
  return(dat.tmp) } )
```

## Boxplot:

```{r}
par(mfrow=c(1,2))
for (i in 1:n.comp.variants){
  boxplot_ils(dat.summ.l[[i]], paste('Before normalization', variant.names[i], sep='_'))
  boxplot_ils(dat.norm.l[[i]], paste('After normalization', variant.names[i], sep='_'))}
par(mfrow=c(1,1))
```

## Line plot of channels medians

```{r}
for (i in 1:n.comp.variants){
  medianlineplot_ils(dat.summ.l[[i]], paste('Before normalization', variant.names[i], sep='_'))
  medianlineplot_ils(dat.norm.l[[i]], paste('After normalization', variant.names[i], sep='_'))}
```

## MA plots

MA plots of two single samples taken from condition 1 and condition 0.125, measured in different MS runs (samples *Mixture2_1:127C* and *Mixture1_2:129N*, respectively).

```{r}
# different unit variants require different computation of fold changes and average abundance: additive or multiplicative scale; see maplot_ils function 
for (i in 1: n.comp.variants){
  p1 <- maplot_ils(dat.nonnorm.summ.w[[i]], 'Mixture2_1:127C', 'Mixture1_2:129N', scale.vec[i], paste('Before normalization', variant.names[i], sep='_'), spiked.proteins)
  p2 <- maplot_ils(dat.norm.summ.w[[i]], 'Mixture2_1:127C', 'Mixture1_2:129N', scale.vec[i], paste('After normalization', variant.names[i], sep='_'), spiked.proteins)
  grid.arrange(p1, p2, ncol=2)}  
```

MA plots of all samples from condition `1` and condition `0.125` (quantification values averaged within condition).

```{r}
# different unit variants require different computation of fold changes and average abundance: additive or multiplicative scale; see maplot_ils function 
samples.num <- sample.info %>% filter(Condition=='1') %>% distinct(Run:Channel) %>% pull
samples.denom <- sample.info %>% filter(Condition=='0.125') %>% distinct(Run:Channel) %>% pull
for (i in 1: n.comp.variants){
  p1 <- maplot_ils(dat.nonnorm.summ.w[[i]], samples.num, samples.denom, scale=scale.vec[i], paste('Before normalization', variant.names[i], sep='_'), spiked.proteins)
  p2 <- maplot_ils(dat.norm.summ.w[[i]], samples.num, samples.denom, scale=scale.vec[i], paste('After normalization', variant.names[i], sep='_'), spiked.proteins)
  grid.arrange(p1, p2, ncol=2)}
```

## CV (coefficient of variation) plots

```{r}
par(mfrow=c(1,2))
for (i in 1: n.comp.variants){
  cvplot_ils(dat=dat.nonnorm.summ.l[[i]], feature.group='Protein', xaxis.group='Condition', title=paste('Before normalization', variant.names[i], sep='_'), abs=T)
  cvplot_ils(dat=dat.norm.summ.l[[i]], feature.group='Protein', xaxis.group='Condition', title=paste('After normalization', variant.names[i], sep='_'), abs=T)}
par(mfrow=c(1,1))
```

## PCA plots

### Using all proteins

```{r}
par(mfrow=c(1,2))
for (i in 1:n.comp.variants){
  pcaplot_ils(dat.nonnorm.summ.w[[i]], info=sample.info, paste('Before normalization', variant.names[i], sep='_'), scale=T)
  pcaplot_ils(dat.norm.summ.w[[i]], info=sample.info, paste('After normalization', variant.names[i], sep='_'))}
par(mfrow=c(1,1))
```

### Using spiked proteins only

```{r}
par(mfrow=c(1,2))
for (i in 1:n.comp.variants){
  pcaplot_ils(dat.nonnorm.summ.w[[i]][rownames(dat.nonnorm.summ.w[[i]]) %in% spiked.proteins,], info=sample.info, paste('Before normalization', variant.names[i], sep='_'), scale=T)
  pcaplot_ils(dat.norm.summ.w[[i]][rownames(dat.norm.summ.w[[i]]) %in% spiked.proteins,], info=sample.info, paste('After normalization', variant.names[i], sep='_'))}
par(mfrow=c(1,1))
```

HC (hierarchical clustering) plots

### Using all proteins

```{r}
par(mfrow=c(1,2))
for (i in 1: n.comp.variants){
  dendrogram_ils(dat.nonnorm.summ.w[[i]], info=sample.info, paste('Before normalization', variant.names[i], sep='_'))
  dendrogram_ils(dat.norm.summ.w[[i]], info=sample.info, paste('After normalization', variant.names[i], sep='_'))}
par(mfrow=c(1, 1))
```

# DEA component

## mixed model (intra-protein correlation) + eBayes

```{r}
dat.dea <- emptyList(variant.names)
for(i in seq_along(dat.dea)){
  dat.dea[[i]] <- lmm_dea(dat=dat.norm.l[[i]], mod.formula='response ~ Condition + (1|Run:Channel)', scale=scale.vec[i], referenceCondition)
}

# character vectors containing logFC and p-values columns
dea.cols <- colnames(dat.dea[[1]])
logFC.cols <- dea.cols[stri_detect_fixed(dea.cols, 'logFC')]
significance.cols <- dea.cols[stri_detect_fixed(dea.cols, 'q.mod')]
n.contrasts <- length(logFC.cols)
```

# Results comparison

## Confusion matrix

```{r, results='asis'}
cm <- conf_mat(dat.dea, 'q.mod', 0.05, spiked.proteins)
print_conf_mat(cm, referenceCondition)
```

## Scatter plots

```{r}
scatterplot_ils(dat.dea, significance.cols, 'q-values', spiked.proteins)
scatterplot_ils(dat.dea, logFC.cols, 'log2FC', spiked.proteins)
```

## Volcano plots

```{r}
for (i in 1:n.contrasts){
  volcanoplot_ils(dat.dea, i, spiked.proteins) }
```

## Violin plots

Let's see whether the spiked protein fold changes make sense
```{r}
# plot theoretical value (horizontal lines) and violin per variant
violinplot_ils(lapply(dat.dea, function(x) x[spiked.proteins, logFC.cols]), referenceCondition)
```

# Conclusions

# Session information

```{r}
sessionInfo()
```