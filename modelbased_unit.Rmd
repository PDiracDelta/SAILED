---
title: "Model-based analysis of isobaric labels data. Unit component."
author: "Piotr Prostko"
date: '`r format(Sys.time(), "%B %d, %Y,%H:%M")`'
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
    theme: flatly
editor_options: 
  chunk_output_type: console
---

```{r, setup, include=FALSE}
# default knitr options for all chunks
knitr::opts_chunk$set(
  message=FALSE,
  warning=FALSE,
  echo=FALSE
)
```

```{r}
library(caret)
#library(DEP)
#library(nlme)
library(lme4)
library(lmerTest)
library(limma)
library(ggplot2)
library(stringi)
library(RColorBrewer)
library(gridExtra)
library(ggfortify)
library(dendextend)
library(psych)
library(xtable)
library(kableExtra)
library(tidyverse)
```

This notebook presents isobaric labeling data analysis strategy that includes model-based normalization [data-driven normalization]. 

We will check how varying analysis components [summarization/normalization/differential abundance testing methods] changes end results of a quantitative proteomic study.

```{r}
source('./other_functions.R')
source('./plotting_functions.R')

# you should either make a symbolic link in this directory
data.list <- readRDS('input_data.rds')
dat.l <- data.list$dat.l # data in long format
dat.w <- data.list$dat.w # data in wide format

# keep spectra with isolation interference <30 and no missing quantification channels
dat.l <- dat.l %>% filter(isoInterOk=='Y' & noNAs=='Y')

# which proteins were spiked in?
spiked.proteins <- dat.l %>% distinct(Protein) %>% filter(stri_detect(Protein, fixed='ups')) %>% pull

# which peptides were identified in each MS run?
unique.pep=dat.l %>% 
  group_by(Run) %>%
  distinct(Peptide) %>% 
  mutate(val=1)
unique.pep <- xtabs(val~Peptide+Run, data=unique.pep)
tmp <- apply(unique.pep, 1, function(x) all(x==1))
inner.peptides <- rownames(unique.pep)[tmp]
```

```{r}
# specify # of varying component variants and their names
n.comp.variants <- 3
variant.names <- c('log2Intensity', 'Intensity', 'log2Ratio')
```

# Unit component

```{r}
dat.unit.l <- vector('list', n.comp.variants)
names(dat.unit.l) <- variant.names
```

## log2 transformation of reporter ion intensities

```{r}
dat.unit.l[[1]] <- dat.l %>% mutate(response=log2(Intensity)) %>% select(-Intensity)
```

## original scale (not log2-transformed) of reporter ion intensities
```{r}
dat.unit.l[[2]] <- dat.l %>% rename(response=Intensity)
```

## log2-transformation of intensity ratios (channel 127C in denominator)

```{r}
# or we can try another channel as reference
denom.df <- dat.l %>% filter(Channel=='127C') %>% rename(denom=Intensity) %>%
  select(Run, Protein, Peptide, RT, Charge, PTM, denom)
dat.unit.l[[3]] <- dat.l %>% left_join(denom.df, by=c('Run', 'Protein', 'Peptide', 'RT', 'Charge', 'PTM')) %>% mutate(response=Intensity/denom) %>% select(-c(Intensity))
```

# Summarization component

```{r}
# no summarization 
dat.summ.l <- dat.unit.l
```

## no summarization

<!-- ## PSM to peptide summarization -->

# Normalization component

## mixed model spec 1

```{r}
dat.norm.l <- lapply(dat.summ.l, function(x) {
  mod <- lmer(response ~ Run + Run:Channel +
                 (1|Protein)  + (1|Peptide), data=x)
  x$response <- residuals(mod)
  return(x)
})
```

<!-- ## mixed model spec 2 -->

<!-- ## mixed model spec 3 -->

# QC plots <!--Normalization diagnostic plots-->

```{r}
# PSM data needs to be aggregated prior to PCA plots and HC plots (they require features in the intersection of all MS runs - this is not possible for PSM data). In order to be consisent, other normalization plots will be based on the aggregated data
dat.summplot.l <- lapply(dat.summ.l, function(x) aggFunc(x, 'response', 'mean')) # before normalization
dat.normplot.l <- lapply(dat.norm.l, function(x) aggFunc(x, 'response', 'mean')) # after normalization

# now create data sets in wide format
# before normalization
dat.summplot.w <- lapply(dat.summplot.l, function(x) {
  dat.tmp <- unclass(xtabs('response~ Peptide + I(Run:Channel)', data=x, drop.unused.levels = TRUE))
  return(dat.tmp)
})

# after normalization
dat.normplot.w <- lapply(dat.normplot.l, function(x) {
  dat.tmp <- unclass(xtabs('response~ Peptide + I(Run:Channel)', data=x, drop.unused.levels = TRUE))
  return(dat.tmp)
})

# make vectors with condition labels and color coding corresponding to samples in wide format data
colors.condition <- tribble(
  ~Condition, ~Col,
  "0.125", 'black',
  "0.5", 'blue',
  "0.667", 'green',
  "1", 'red'
)
# sufficient to do that only on the first items of dat.normplot.l and dat.normplot.w lists
colors.condition.map <- dat.normplot.l[[1]] %>% distinct(Run:Channel, Condition) %>% left_join(colors.condition, by='Condition')
ord <- match(colnames(dat.normplot.w[[1]]), colors.condition.map$`Run:Channel`)

# important: these two vectors contain colors and condition labels corresponding to data in wide format
cols.vec <- colors.condition.map[ord, 'Col']  %>% pull
conditions.vec <- colors.condition.map[ord, 'Condition']  %>% pull
```

Boxplots:

```{r}
for (i in 1: n.comp.variants){
  par(mfrow=c(1,2))
    boxplot.ils(dat.summ.l[[i]], paste('Before normalization', variant.names[i], sep='_'))
    boxplot.ils(dat.norm.l[[i]], paste('After normalization', variant.names[i], sep='_'))
  par(mfrow=c(1,1))
}
```

MA plots:

MA plots of two single samples taken from condition 1 and condition 0.125, measured in different MS runs (samples *Mixture2_1:127C* and *Mixture1_2:129N*, respectively).

```{r}
# different unit variants require different computation of fold changes and average abuandance: additive or multiplicative scale; see maplot.ils function 
scale.vec <- c('log', 'raw', 'log') 

for (i in 1: n.comp.variants){
  p1 <- maplot.ils(dat.summplot.w[[i]], 'Mixture2_1:127C', 'Mixture1_2:129N', scale.vec[i], paste('Before normalization', variant.names[i], sep='_'))
  
  p2 <- maplot.ils(dat.normplot.w[[i]], 'Mixture2_1:127C', 'Mixture1_2:129N', scale.vec[i], paste('After normalization', variant.names[i], sep='_'))
  
  grid.arrange(p1, p2, ncol=2)  
}
```

MA plots of all samples from condition `1` and condition `0.125` (quantification values averaged within condition).

```{r}
# different unit variants require different computation of fold changes and average abuandance: additive or multiplicative scale; see maplot.ils function 
scale.vec <- c('log', 'raw', 'log') 
samples.num <- dat.summplot.l[[1]] %>% filter(Condition=='1') %>% distinct(Run:Channel) %>% pull
samples.denom <- dat.summplot.l[[1]] %>% filter(Condition=='0.125') %>% distinct(Run:Channel) %>% pull
for (i in 1: n.comp.variants){
  p1 <- maplot.ils(dat.summplot.w[[i]], samples.num, samples.denom, scale=scale.vec[i], paste('Before normalization', variant.names[i], sep='_'))
  
  p2 <- maplot.ils(dat.normplot.w[[i]], samples.num, samples.denom, scale=scale.vec[i], paste('After normalization', variant.names[i], sep='_'))
  
  grid.arrange(p1, p2, ncol=2)  
}
```

CV (coefficient of variation) plots:

PCA plots:

```{r}
# create a shorter version of run variable to present on legend
run.labels <- stri_replace(unlist(lapply(stri_split(colnames(dat.summplot.w[[1]]), fixed=':'), function(x) x[1])), fixed='Mixture', 'Mix')

for (i in 1: n.comp.variants){
  par(mfrow=c(1, 2))
    pcaplot.ils(dat.summplot.w[[i]], run.labels, conditions.vec, cols.vec, paste('Before normalization', variant.names[i], sep='_'))
    pcaplot.ils(dat.normplot.w[[i]], run.labels, conditions.vec, cols.vec, paste('After normalization', variant.names[i], sep='_'))
  par(mfrow=c(1, 1))  
}
```

HC (hierarchical clustering) plots:

```{r}
# !!! only 1000 first record selected to speed up knitting, remove in the final version!!!
for (i in 1: n.comp.variants){
  par(mfrow=c(1, 2))
    dendrogram.ils(dat.summplot.w[[i]][1:1000,], cols.vec, paste('Before normalization', variant.names[i], sep='_'))
    dendrogram.ils(dat.normplot.w[[i]][1:100,], cols.vec, paste('After normalization', variant.names[i], sep='_'))
  par(mfrow=c(1, 1))  
}
```

# DEA component

```{r}
shared.peptides <- dat.l %>% filter(shared.peptide=='Y') %>% 
  distinct(Peptide) %>% pull
```

## mixed model (intra-protein correlation) + eBayes

```{r}
# !!! only 1000 first record selected to speed up knitting, remove in the final version!!!
dat.dea <- lapply(dat.norm.l, function(x){
  tmp <- x %>% filter(!(Peptide %in% shared.peptides)) # remove shared peptides before DEA
  out <- mixed.model.dea(dat=tmp[1:1000,], mod.formula='response ~ Condition + (1|Run:Channel)',
                         conditions=c('1', '0.125')) 
  return(out)
})

# create fake variables to mimic the output format of Joris's moderated t-test function - this part will be removed
condition.levels <- levels(dat.norm.l[[1]]$Condition)
ref.condition <- condition.levels[1]
contrast.names <- paste0('cond', condition.levels[-c(1, length(condition.levels))], '-cond', ref.condition)
dea.vars <- c('logFC','t.ord','t.mod','p.ord','p.mod','q.ord','q.mod')

for (i in 1: length(dat.dea)){
    dat1 <- dat.dea[[i]][, dea.vars]
    dat2 <- dat1
    dat3 <- dat1
    colnames(dat1) <- paste(colnames(dat1), contrast.names[1], sep='_')
    colnames(dat2) <- paste(colnames(dat2), contrast.names[2], sep='_')
    colnames(dat3) <- paste(colnames(dat3), contrast.names[3], sep='_')
    rnames <-  rownames(dat.dea[[i]])
    dat.dea[[i]] <- bind_cols(dat1, dat2, dat3)
    rownames(dat.dea[[i]]) <- rnames
}
# 

# character vectors containing logFC and p-values columns
dea.cols <- colnames(dat.dea[[1]])
logFC.cols <- dea.cols[stri_detect_fixed(dea.cols, 'logFC')]
q.cols <- dea.cols[stri_detect_fixed(dea.cols, 'q.mod')]
n.contrasts <- length(logFC.cols)
```

<!-- ## DEqMS -->

# Results comparison

Confusion matrix:

```{r, results='asis'}
n.comp.variants <- 3
for (i in 1:n.comp.variants){
  cat("\n")
  cat('Confusion matrix for variant: ', variant.names[i])
  cm <- conf.mat(dat.dea[[i]], 'q.mod', 0.05)
  cat("\n")
  print(kable(cm$tab))
  cat("\n")
  print(kable(cm$metrics))
  cat("\n")
}
```

Scatter plots:

```{r}
for (i in 1: n.comp.variants){
  pairs.panels(dat.dea[[i]][, q.cols], method='spearman', main=paste("Spearman's correlation of adjusted p-values", variant.names[i], sep='_' ))
  
  pairs.panels(dat.dea[[i]][, logFC.cols], method='spearman', main=paste("Spearman's correlation of log2FC", variant.names[i], sep='_' ))
}
```

Volcano plots:

```{r}
for (i in 1:n.comp.variants){
  volcanoplot.ils(dat.dea[[i]], variant.names[i])
}
```

Violin plot:

# Conclusions

# Session information

```{r}
sessionInfo()
```








