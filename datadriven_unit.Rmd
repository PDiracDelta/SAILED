---
title: "Data-driven analysis of isobaric labels data. Unit component."
author: "Joris Van Houtven"
date: '`r format(Sys.time(), "%B %d, %Y,%H:%M")`'
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
    theme: flatly
editor_options: 
  chunk_output_type: console
---
  
```{r, setup, include=FALSE}
# default knitr options for all chunks
knitr::opts_chunk$set(
  message=FALSE,
  warning=FALSE,
  echo=FALSE
)
```

```{r}
library(caret)
# library(DEP)
# library(nlme)
# library(lme4)
# library(lmerTest)
library(limma)
library(ggplot2)
library(stringi)
library(RColorBrewer)
library(gridExtra)
library(psych)
library(kableExtra)
library(psych)
library(tidyverse)
library(CONSTANd)  # install from source: https://github.com/PDiracDelta/CONSTANd/
```

This notebook presents isobaric labeling data analysis strategy that includes data-driven normalization. 

We will check how varying analysis components [summarization/normalization/differential abundance testing methods] changes end results of a quantitative proteomic study.

```{r}
source('./other_functions.R')
source('./plotting_functions.R')

# you should either make a symbolic link in this directory
data.list <- readRDS('input_data.rds')
dat.l <- data.list$dat.l # data in long format
# dat.w <- data.list$dat.w # data in wide format
if ('X' %in% colnames(dat.l)) { dat.l$X <- NULL }

# remove shared peptides
shared.peptides <- dat.l %>% filter(!shared.peptide)

# keep spectra with isolation interference <30 and no missing quantification channels
dat.l <- dat.l %>% filter(isoInterOk & noNAs)

# which proteins were spiked in?
spiked.proteins <- dat.l %>% distinct(Protein) %>% filter(stri_detect(Protein, fixed='ups')) %>% pull %>% as.character

# which peptides were identified in each MS run?
unique.pep=dat.l %>% 
  group_by(Run) %>%
  distinct(Peptide) %>% 
  mutate(val=1)
unique.pep <- xtabs(val~Peptide+Run, data=unique.pep)
tmp <- apply(unique.pep, 1, function(x) all(x==1))
inner.peptides <- rownames(unique.pep)[tmp]
```

```{r}
# specify # of varying component variants and their names
n.comp.variants <- 3
variant.names <- c('log2Intensity', 'Intensity', 'log2Ratio')
# pick reference channel and condition for making plots / doing DEA
referenceChannel <- '127C'
referenceCondition <- '0.5'
```

# Unit component

```{r}
dat.unit.l <- vector('list', n.comp.variants)
names(dat.unit.l) <- variant.names
```

## log2 transformation of reporter ion intensities

```{r}
dat.unit.l[[1]] <- dat.l %>% mutate(response=log2(Intensity)) %>% select(-Intensity)
```

## original scale (not log-transformed) of reporter ion intensities
```{r}
dat.unit.l[[2]] <- dat.l %>% rename(response=Intensity)
```

## log2-transformation of intensity ratios (channel 127C in denominator)

```{r}
# or we can try another channel as reference
denom.df <- dat.l %>% filter(Channel==referenceChannel) %>% rename(denom=Intensity) %>%
  select(Run, Protein, Peptide, RT, Charge, PTM, denom)
dat.unit.l[[3]] <- dat.l %>% left_join(denom.df, by=c('Run', 'Protein', 'Peptide', 'RT', 'Charge', 'PTM')) %>% mutate(response=Intensity/denom) %>% select(-c(Intensity))
```

# Normalization component

```{r}
# switch to wide format
dat.unit.w <- lapply(dat.unit.l, function(x) {
  pivot_wider(data = x, id_cols=-one_of(c('Condition', 'BioReplicate')), names_from=Channel, values_from=response)
})
# dat.unit.w2 <- lapply(dat.unit.l, function(x) {
#   pivot_wider(data = x, id_cols=-one_of(c('Condition', 'BioReplicate')), names_from=c('Run','Channel'), values_from=response)
# })
```

## CONSTANd

```{r}
# dat.unit.l entries are in long format so all have same colnames and no quanCols
quanCols = setdiff(colnames(dat.unit.w[[1]]), colnames(dat.unit.l[[1]]))
dat.norm.w <- lapply(dat.unit.w, function(x) {
  x.split <- split(x, x$Run)  # apply CONSTANd to each Run separately
  x.split.norm  <- lapply(x.split, function(y) {
    y[,quanCols] <- CONSTANd(y[,quanCols])$normalized_data
    return(y)
  })
  return(bind_rows(x.split.norm))
})
```

<!-- ## Normalization method 2 -->

<!-- ## Normalization method 3 -->

# Summarization component

Summarize quantification values from PSM to peptide (first step) to protein (second step).

## Median summarization (PSM to peptide to protein)

```{r}
# normalized data
study.design=read.delim('msstatstmt_studydesign.csv')
dat.norm.summ.w <- lapply(dat.norm.w, function(x) {
  # group by (run,)protein,peptide then summarize twice (once on each level)
  y <- x %>% group_by(Run, Protein, Peptide) %>% summarise_at(.vars = quanCols, .funs = median) %>% summarise_at(.vars = quanCols, .funs = median) %>% ungroup()
  return(y)
})
```

Notice that the row sums are not equal to Ncols anymore, because the median summarization
does not preserve them (but mean summarization does).

Let's also summarize the non-normalized data for comparison in the next section.
```{r}
# non-normalized data
dat.nonnorm.summ.w <- lapply(dat.unit.w, function(x) {
  # group by (run,)protein,peptide then summarize twice (once on each level)
  y <- x %>% group_by(Run, Protein, Peptide) %>% summarise_at(.vars = quanCols, .funs = median) %>% summarise_at(.vars = quanCols, .funs = median) %>% ungroup()
  return(y)
})
```

<!-- ## summarization method 2 -->

<!-- ## summarization method 3 -->


# QC plots <!--Normalization diagnostic plots-->

```{r}
# make data completely wide (also across runs)

## non-normalized data
dat.nonnorm.summ.w2 <- lapply(dat.nonnorm.summ.w, function(x) {
  dat.tmp <- x %>% pivot_wider(names_from = Run, values_from = all_of(quanCols))
  return(dat.tmp)
})

## normalized data
dat.norm.summ.w2 <- lapply(dat.norm.summ.w, function(x) {
  dat.tmp <- x %>% pivot_wider(names_from = Run, values_from = all_of(quanCols))
  return(dat.tmp)
})

# make vectors with condition labels and color coding corresponding to samples in wide format data
colors.condition <- tribble(
  ~Condition, ~Col,
  "0.125", 'black',
  "0.5", 'blue',
  "0.667", 'green',
  "1", 'red'
)
run_channel_condition <- expand_grid(Channel=quanCols, Run=unique(study.design$Run)) %>% left_join(study.design, by=c('Channel', 'Run')) %>% select(Run, Channel, Condition)
colors.condition.map <- run_channel_condition %>% unite(Channel, Channel:Run) %>% left_join(colors.condition, by='Condition')
ord <- match(colnames(dat.norm.summ.w2[[1]]), colors.condition.map$Channel)
ord <- ord[!is.na(ord)]  # drop first entry which is NA

# important: these two vectors contain colors and condition labels corresponding to data in wide2 format
cols.vec <- colors.condition.map[ord, 'Col'] %>% pull
conditions.vec <- colors.condition.map[ord, 'Condition'] %>% pull
```

## Boxplots:

```{r}
# use (half-)wide format
for (i in 1: n.comp.variants){
  par(mfrow=c(1,2))
    boxplot.w(dat.nonnorm.summ.w[[i]],study.design, paste('Raw', variant.names[i], sep='_'))
    boxplot.w(dat.norm.summ.w[[i]], study.design, paste('Normalized', variant.names[i], sep='_'))
  par(mfrow=c(1,1))
}
```

## MA plots:

MA plots of two single samples taken from condition 1 and condition 0.125, measured in different MS runs (samples *Mixture2_1:127C* and *Mixture1_2:129N*, respectively).

```{r}
# different unit variants require different computation of fold changes and average abuandance: additive or multiplicative scale; see maplot.ils function 
scale.vec <- c('log', 'raw', 'log') 
# use wide2 format
for (i in 1: n.comp.variants){
  p1 <- maplot.ils(dat.nonnorm.summ.w2[[i]], '127C_Mixture2_1', '129N_Mixture1_2', scale.vec[i], paste('Before normalization', variant.names[i], sep='_'))
  
  p2 <- maplot.ils(dat.norm.summ.w2[[i]], '127C_Mixture2_1', '129N_Mixture1_2', scale.vec[i], paste('After normalization', variant.names[i], sep='_'))
  
  grid.arrange(p1, p2, ncol=2)  
}
```

## MA plots of all samples from condition `1` and condition `0.125` (quantification values averaged within condition).

```{r}
# different unit variants require different computation of fold changes and average abuandance: additive or multiplicative scale; see maplot.ils function 
scale.vec <- c('log', 'raw', 'log') 
channels.num <- colors.condition.map %>% filter(Condition=='1') %>% select(Channel) %>% pull
channels.denom <- colors.condition.map %>% filter(Condition=='0.125') %>% select(Channel) %>% pull
for (i in 1: n.comp.variants){
  p1 <- maplot.ils(dat.nonnorm.summ.w2[[i]], channels.num, channels.denom, scale=scale.vec[i], paste('Before normalization', variant.names[i], sep='_'))
  
  p2 <- maplot.ils(dat.norm.summ.w2[[i]], channels.num, channels.denom, scale=scale.vec[i], paste('After normalization', variant.names[i], sep='_'))
  
  grid.arrange(p1, p2, ncol=2)  
}
```

## CV (coefficient of variation) plots:

## PCA plots:

### Using all proteins
```{r}
# create a shorter version of run variable to present on legend ([-1] to avoid Protein col)
run.labels <- stri_replace(unlist(lapply(stri_split(colnames(dat.norm.summ.w2[[1]])[-1], fixed='_'), function(x) paste(x[2],x[3],sep = '_'))), fixed='Mixture', 'Mix')

for (i in seq_along(dat.norm.summ.w2)){
  par(mfrow=c(1, 2))
  # select only the spiked.proteins
  pcaplot.ils(dat.nonnorm.summ.w2[[i]] %>% select(-'Protein'), run.labels, conditions.vec, cols.vec, paste('Before normalization', variant.names[i], sep='_'))
  pcaplot.ils(dat.norm.summ.w2[[i]] %>% select(-'Protein'), run.labels, conditions.vec, cols.vec, paste('After normalization', variant.names[i], sep='_'))
  par(mfrow=c(1, 1))  
}
```

### Using spiked proteins only
```{r}
# create a shorter version of run variable to present on legend ([-1] to avoid Protein col)
run.labels <- stri_replace(unlist(lapply(stri_split(colnames(dat.norm.summ.w2[[1]])[-1], fixed='_'), function(x) paste(x[2],x[3],sep = '_'))), fixed='Mixture', 'Mix')

for (i in seq_along(dat.norm.summ.w2)){
  par(mfrow=c(1, 2))
    pcaplot.ils(dat.nonnorm.summ.w2[[i]] %>% filter(Protein %in% spiked.proteins) %>% select(-'Protein'), run.labels, conditions.vec, cols.vec, paste('Before normalization', variant.names[i], sep='_'))
    pcaplot.ils(dat.norm.summ.w2[[i]] %>% filter(Protein %in% spiked.proteins) %>% select(-'Protein'), run.labels, conditions.vec, cols.vec, paste('After normalization', variant.names[i], sep='_'))
  par(mfrow=c(1, 1))  
}
```

## HC (hierarchical clustering) plots:

Only use spiked proteins

TO DO:
- !!! only 1000 first record selected to speed up knitting, remove in the final version!!!
- also use short label names like in PCA plot
- unify the list of args across pcaplot.ils and dendrogram.ils. Make sure labeling and color picking is done in the same location (either inside or outside the function)

```{r}
for (i in seq_along(dat.norm.summ.w2)){
  par(mfrow=c(1, 2))
    dendrogram.ils(dat.nonnorm.summ.w2[[i]][1:1000,] %>% filter(Protein %in% spiked.proteins) %>% select(-Protein), cols.vec, paste('Before normalization', variant.names[i], sep='_'))
    dendrogram.ils(dat.norm.summ.w2[[i]][1:1000,] %>% filter(Protein %in% spiked.proteins) %>% select(-Protein), cols.vec, paste('After normalization', variant.names[i], sep='_'))
  par(mfrow=c(1, 1))  
}
```

# DEA component

## Moderated t-test

TODO:
- Also try to log-transform the intensity case, to see if there are large differences in the t-test results.
  - done. remove this code?
NOTE:
- actually, lmFit (used in moderated_ttest) was built for log2-transformed data. However, supplying untransformed intensities can also work. This just means that the effects in the linear model are also additive on the untransformed scale, whereas for log-transformed data they are multiplicative on the untransformed scale. Also, there may be a bias which occurs from biased estimates of the population means in the t-tests, as mean(X) is not equal to exp(mean(log(X))).
```{r}
#{ INVESTIGATE late log2 transform
dat.norm.summ.w2$Intensity_lateLog2 <- dat.norm.summ.w2$Intensity
quanCols.prefixed <- colnames(dat.norm.summ.w2$Intensity %>% select(-Protein))
dat.norm.summ.w2$Intensity_lateLog2[,quanCols.prefixed] <- log2(dat.norm.summ.w2$Intensity[,quanCols.prefixed])
variant.names <- names(dat.norm.summ.w2)
scale.vec <- c(scale.vec, 'log')
n.comp.variants <- n.comp.variants + 1
#}
design.matrix <- get_design_matrix(referenceCondition, study.design)
dat.dea <- emptyList(names(dat.norm.summ.w2))
for (i in seq_along(dat.norm.summ.w2)) {
  this_scale <- scale.vec[match(names(dat.dea)[i], variant.names)]
  d <- column_to_rownames(as.data.frame(dat.norm.summ.w2[[i]]), 'Protein')
  dat.dea[[i]] <- moderated_ttest(dat=d, design.matrix, scale=this_scale)
}
```

<!-- Wilcoxon test -->

<!-- Permutation test -->

# Results comparison

Confusion matrix:

```{r, results='asis'}
for (i in 1:n.comp.variants){
  cat("\n")
  cat('Confusion matrix for variant: ', variant.names[i])
  cm <- conf.mat(dat.dea[[i]], 'q.mod', 0.05)
  cat("\n")
  print(kable(cm$tab))
  cat("\n")
  print(kable(cm$metrics))
  cat("\n")
}
```

Scatter plots:

```{r}
# character vectors containing logFC and p-values columns
dea.cols <- colnames(dat.dea[[1]])
logFC.cols <- dea.cols[stri_detect_fixed(dea.cols, 'logFC')]
q.cols <- dea.cols[stri_detect_fixed(dea.cols, 'q.mod')]
n.contrasts <- length(logFC.cols)

for (i in seq(n.comp.variants)){
  pairs.panels(dat.dea[[i]][, q.cols], method='spearman', main=paste("Spearman's correlation of adjusted p-values", variant.names[i], sep='_' ))
  
  pairs.panels(dat.dea[[i]][, logFC.cols], method='spearman', main=paste("Spearman's correlation of log2FC", variant.names[i], sep='_' ))
}
```

Volcano plots:

```{r}
for (i in 1:n.comp.variants){
  volcanoplot.ils(dat.dea[[i]], variant.names[i])
}
```

Violin plots:

Let's see whether the spiked protein fold changes make sense
```{r}
# plot theoretical value (horizontal lines) and violin per condition
dat.spiked.logfc <- lapply(dat.dea, function(x) x[spiked.proteins,logFC.cols])
dat.spiked.logfc.l <- lapply(dat.spiked.logfc, function(x) {
  x %>% rename_with(function(y) sapply(y, function(z) strsplit(z, '_')[[1]][2])) %>% pivot_longer(cols = everything(), names_to = 'condition', values_to = 'logFC') %>% add_column(Protein=rep(rownames(x), each=length(colnames(x)))) })
violinplot.ils(lapply(dat.spiked.logfc.l, filter, condition != referenceCondition))
```


# Conclusions

# Session information

```{r}
sessionInfo()
```